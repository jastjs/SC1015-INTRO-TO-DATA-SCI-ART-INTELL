{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotly Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "import json\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: resale-flat-prices-based-on-approval-date-2000-feb-2012 is being split into two due to exceeding the size limit for Github.\n",
    "- resale-flat-prices-based-on-approval-date-2000-feb-2005.csv\n",
    "- resale-flat-prices-based-on-approval-date-2006-2012.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1990 = pd.read_csv('Resale Flat Prices/resale-flat-prices-based-on-approval-date-1990-1999.csv')\n",
    "df_2000 = pd.read_csv('Resale Flat Prices/resale-flat-prices-based-on-approval-date-2000-feb-2005.csv')\n",
    "df_2006 = pd.read_csv('Resale Flat Prices/resale-flat-prices-based-on-approval-date-2006-2012.csv')\n",
    "df_2012 = pd.read_csv('Resale Flat Prices/resale-flat-prices-based-on-registration-date-from-mar-2012-to-dec-2014.csv')\n",
    "df_2015 = pd.read_csv('Resale Flat Prices/resale-flat-prices-based-on-registration-date-from-jan-2015-to-dec-2016.csv')\n",
    "df_2017 = pd.read_csv('Resale Flat Prices/resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.concat([df_1990, df_2000, df_2006, df_2012, df_2015, df_2017])\n",
    "df_main = df_main.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_main.month.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.town.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.flat_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.storey_range.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.flat_model.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.remaining_lease.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region \n",
    "\n",
    "df_main['town'] = df_main['town'].replace(['ANG MO KIO'],'NORTH-EAST REGION')\n",
    "df_main['town'] = df_main['town'].replace(['BEDOK'],'EAST REGION')\n",
    "df_main['town'] = df_main['town'].replace(['BISHAN'],'CENTRAL REGION')\n",
    "df_main['town'] = df_main['town'].replace(['BUKIT BATOK'],'WEST REGION')\n",
    "df_main['town'] = df_main['town'].replace(['BUKIT MERAH'],'CENTRAL REGION')\n",
    "df_main['town'] = df_main['town'].replace(['BUKIT TIMAH'],'CENTRAL REGION')\n",
    "df_main['town'] = df_main['town'].replace(['CENTRAL AREA'],'CENTRAL REGION')\n",
    "df_main['town'] = df_main['town'].replace(['CHOA CHU KANG'],'WEST REGION')\n",
    "df_main['town'] = df_main['town'].replace(['CLEMENTI'],'WEST REGION')\n",
    "df_main['town'] = df_main['town'].replace(['GEYLANG'],'CENTRAL REGION')\n",
    "df_main['town'] = df_main['town'].replace(['HOUGANG'],'NORTH-EAST REGION')\n",
    "df_main['town'] = df_main['town'].replace(['JURONG EAST'],'WEST REGION')\n",
    "df_main['town'] = df_main['town'].replace(['JURONG WEST'],'WEST REGION')\n",
    "df_main['town'] = df_main['town'].replace(['KALLANG/WHAMPOA'],'CENTRAL REGION')\n",
    "df_main['town'] = df_main['town'].replace(['MARINE PARADE'],'CENTRAL REGION')\n",
    "df_main['town'] = df_main['town'].replace(['QUEENSTOWN'],'CENTRAL REGION')\n",
    "df_main['town'] = df_main['town'].replace(['SENGKANG'],'NORTH-EAST REGION')\n",
    "df_main['town'] = df_main['town'].replace(['SERANGOON'],'NORTH-EAST REGION')\n",
    "df_main['town'] = df_main['town'].replace(['TAMPINES'],'EAST REGION')\n",
    "df_main['town'] = df_main['town'].replace(['TOA PAYOH'],'CENTRAL REGION')\n",
    "df_main['town'] = df_main['town'].replace(['WOODLANDS'],'NORTH REGION')\n",
    "df_main['town'] = df_main['town'].replace(['YISHUN'],'NORTH REGION')\n",
    "df_main['town'] = df_main['town'].replace(['LIM CHU KANG'],'NORTH REGION')\n",
    "df_main['town'] = df_main['town'].replace(['SEMBAWANG'],'NORTH REGION')\n",
    "df_main['town'] = df_main['town'].replace(['BUKIT PANJANG'],'WEST REGION')\n",
    "df_main['town'] = df_main['town'].replace(['PASIR RIS'],'EAST REGION')\n",
    "df_main['town'] = df_main['town'].replace(['PUNGGOL'],'NORTH-EAST REGION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storey Range\n",
    "\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['10 TO 12'],'01 TO 15')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['04 TO 06'],'01 TO 15')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['07 TO 09'],'01 TO 15')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['01 TO 03'],'01 TO 15')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['13 TO 15'],'01 TO 15')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['19 TO 21'],'16 TO 30')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['16 TO 18'],'16 TO 30')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['25 TO 27'],'16 TO 30')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['22 TO 24'],'16 TO 30')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['28 TO 30'],'16 TO 30')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['31 TO 33'],'16 TO 30')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['40 TO 42'],'31 TO 45')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['37 TO 39'],'31 TO 45')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['34 TO 36'],'31 TO 45')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['06 TO 10'],'01 TO 15')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['01 TO 05'],'01 TO 15')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['11 TO 15'],'01 TO 15')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['16 TO 20'],'16 TO 30')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['21 TO 25'],'16 TO 30')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['26 TO 30'],'16 TO 30')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['36 TO 40'],'31 TO 45')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['31 TO 35'],'31 TO 45')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['46 TO 48'],'31 TO 45')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['43 TO 45'],'31 TO 45')\n",
    "df_main['storey_range'] = df_main['storey_range'].replace(['49 TO 51'],'31 TO 45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting month into Month and Year\n",
    "\n",
    "df_main[['Year', 'Month']] = df_main['month'].str.split('-', expand=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lease Commence Date\n",
    "\n",
    "df_main['Year'] = df_main['Year'].astype(str).astype(int) \n",
    "\n",
    "df_main['lease_left']=(99 - (df_main['Year'] - df_main['lease_commence_date'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flat differences\n",
    "\n",
    "Multi generation flat:\n",
    "- Current - 3 rooms (2 master room, 1 normal room) [excluding living room]\n",
    "- Previous (1980s) - 4-room or 5-room flat with an adjoining studio apartment that had a separate entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing MULTI-GENERATION TO MULTI GENERATION\n",
    "\n",
    "df_main['flat_type'] = df_main['flat_type'].replace(['MULTI-GENERATION'],'MULTI GENERATION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type S1 and S2: (i.e. The Pinnacle@Duxton)\n",
    "- Special types, different unit variations – with dissimilar combinations of features such as extended bays, balconies, bay windows and planter areas.\n",
    "\n",
    "All the different models (Improved, Simplified etc):\n",
    "- Refers to the different model of each flat types, normally means floor plan is different, but all means the same type.\n",
    "\n",
    "Adjoined flat are 2 individual flats purchased side by side, and the owners link both units together.\n",
    "\n",
    "Loft apartment is flats with high ceiling, 1 staircase and 1 room on the top, normally located at the top of the building (something like penthouse but HDB version)\n",
    "\n",
    "Comparison between following models:\n",
    "- Apartment (1-level)\n",
    "- Maisonette (2-level, normally multiple units in 1 HDB building)\n",
    "- Terrace (2-levels, but a stand-alone building)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flat Model\n",
    "\n",
    "df_main['flat_model'] = df_main['flat_model'].replace(['MODEL A-MAISONETTE','IMPROVED-MAISONETTE',\n",
    "                                                       'Model A-Maisonette','Improved-Maisonette', \n",
    "                                                       'Premium Maisonette', 'Maisonette'],\n",
    "                                                       'MAISONETTE')\n",
    "df_main['flat_model'] = df_main['flat_model'].replace(['PREMIUM APARTMENT','Apartment','Premium Apartment'],\n",
    "                                                       'APARTMENT')\n",
    "df_main['flat_model'] = df_main['flat_model'].replace(['Improved'],'IMPROVED')\n",
    "df_main['flat_model'] = df_main['flat_model'].replace(['New Generation'],'NEW GENERATION')\n",
    "df_main['flat_model'] = df_main['flat_model'].replace(['Model A'],'MODEL A')\n",
    "df_main['flat_model'] = df_main['flat_model'].replace(['Standard'],'STANDARD')\n",
    "df_main['flat_model'] = df_main['flat_model'].replace(['Simplified'],'SIMPLIFIED')\n",
    "df_main['flat_model'] = df_main['flat_model'].replace(['2-room','Model A2'],'2-ROOM')\n",
    "df_main['flat_model'] = df_main['flat_model'].replace(['Terrace'],'TERRACE')\n",
    "df_main['flat_model'] = df_main['flat_model'].replace(['Multi Generation'],'MULTI GENERATION')\n",
    "df_main['flat_model'] = df_main['flat_model'].replace(['Adjoined flat'],'ADJOINED FLAT')\n",
    "df_main['flat_model'] = df_main['flat_model'].replace(['Type S1', 'Type S2'],'TYPE S')\n",
    "df_main['flat_model'] = df_main['flat_model'].replace(['Premium Apartment Loft'],'LOFT APARTMENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_main[['flat_type','block','street_name','storey_range','floor_area_sqm','flat_model',\n",
    "                      'resale_price','Year','lease_left','town']]\n",
    "df_cleaned = df_cleaned.rename(columns={\"Year\": \"year\", 'town' : 'region'})\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating the data into decades.\n",
    "- 1990 to 1999\n",
    "- 2000 to 2009\n",
    "- 2010 to 2019\n",
    "- 2020 onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_90 = df_cleaned[df_cleaned['year'] < 2000]\n",
    "df_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_00 = df_cleaned[(df_cleaned['year'] >= 2000) & (df_cleaned['year'] < 2010)]\n",
    "df_00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10 = df_cleaned[(df_cleaned['year'] >= 2010) & (df_cleaned['year'] < 2020)]\n",
    "df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20 = df_cleaned[df_cleaned['year'] >= 2020]\n",
    "df_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Geojson/master-plan-2019-region-boundary-no-sea-geojson.geojson')\n",
    " \n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['features'][0]['properties']['region'] = 'WEST REGION'\n",
    "data['features'][1]['properties']['region'] = 'NORTH REGION'\n",
    "data['features'][2]['properties']['region'] = 'NORTH-EAST REGION'\n",
    "data['features'][3]['properties']['region'] = 'EAST REGION'\n",
    "data['features'][4]['properties']['region'] = 'CENTRAL REGION'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cleaned[\"region\"][0])\n",
    "print(data['features'][0]['properties'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall across the years from 1990 to 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_main = pd.DataFrame(df_cleaned[[\"floor_area_sqm\",\"resale_price\",\"lease_left\"]])\n",
    "numeric_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_dist(df):\n",
    "\n",
    "    f, axes = plt.subplots(3, 3, figsize=(18, 18))\n",
    "    count = 0\n",
    "    for var in df:\n",
    "        sns.boxplot(data = df[var], orient = \"h\", ax = axes[count,0])\n",
    "        sns.histplot(data = df[var], ax = axes[count,1])\n",
    "        sns.violinplot(data = df[var], orient = \"h\", ax = axes[count,2])\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the Distributions of All Variables\n",
    "numeric_dist(numeric_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_corr(df):\n",
    "    \n",
    "    print(df.corr())\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(df.corr(), vmin = -1, vmax = 1, linewidths = 1,\n",
    "               annot = True, fmt = \".2f\", annot_kws = {\"size\": 18}, cmap = \"RdBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Heatmap of the Correlation Matrix\n",
    "numeric_corr(numeric_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data = numeric_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_type_flat_model(df):\n",
    "    \n",
    "    f = plt.figure(figsize=(20, 15))\n",
    "    sns.heatmap(df.groupby(['flat_type', 'flat_model']).size().unstack(), \n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 18}, cmap = \"Blues\", fmt=\".0f\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Flat Type vs Flat Model\n",
    "flat_type_flat_model(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_type_region(df):\n",
    "\n",
    "    f = plt.figure(figsize=(15, 10))\n",
    "    sns.heatmap(df.groupby(['flat_type', 'region']).size().unstack(), \n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 18}, cmap = \"Blues\", fmt=\".0f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Flat Type vs Region\n",
    "flat_type_region(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storey_range_region(df):\n",
    "    \n",
    "    f = plt.figure(figsize=(10, 5))\n",
    "    sns.heatmap(df.groupby(['storey_range', 'region']).size().unstack(), \n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 18}, cmap = \"Blues\", fmt=\".0f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Storey Range vs Region\n",
    "storey_range_region(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resale_price_region(df):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 10))    \n",
    "    sns.boxplot(x ='resale_price', y ='region', data = df)\n",
    "    ax.xaxis.set_major_formatter(ticker.EngFormatter())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Resale Price vs Region\n",
    "resale_price_region(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resale_price_flat_model(df):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))    \n",
    "    sns.boxplot(x ='resale_price', y ='flat_model', data = df)\n",
    "    ax.xaxis.set_major_formatter(ticker.EngFormatter())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Resale Price vs Flat Model\n",
    "resale_price_flat_model(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overall = df_cleaned.groupby(['region']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_visual(df):\n",
    "    \n",
    "    fig = px.choropleth_mapbox(df, geojson=data, color=\"resale_price\",\n",
    "                           locations=\"region\", featureidkey=\"properties.region\",\n",
    "                           center={\"lat\": 1.3302, \"lon\": 103.8519},\n",
    "                           color_continuous_scale = 'blues',\n",
    "                           mapbox_style=\"carto-positron\", zoom=10)\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Map Visualisation for Overall Average Resale Price per Region\n",
    "map_visual(df_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1990 to 1999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_90 = pd.DataFrame(df_90[[\"floor_area_sqm\",\"resale_price\",\"lease_left\"]])\n",
    "numeric_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the Distributions of All Variables\n",
    "numeric_dist(numeric_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the Correlation Matrix\n",
    "numeric_corr(numeric_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = numeric_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Flat Type vs Flat Model\n",
    "flat_type_flat_model(df_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Flat Type vs Region\n",
    "flat_type_region(df_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Storey Range vs Region\n",
    "storey_range_region(df_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Resale Price vs Region\n",
    "resale_price_region(df_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Resale Price vs Flat Model\n",
    "resale_price_flat_model(df_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_90overall = df_90.groupby(['region']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Visualisation for Overall Average Resale Price per Region\n",
    "map_visual(df_90overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2000 to 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_00= pd.DataFrame(df_00[[\"floor_area_sqm\",\"resale_price\",\"lease_left\"]])\n",
    "numeric_00.reset_index(drop=True, inplace=True)\n",
    "numeric_00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the Distributions of All Variables\n",
    "numeric_dist(numeric_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the Correlation Matrix\n",
    "numeric_corr(numeric_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data = numeric_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Flat Type vs Flat Model\n",
    "flat_type_flat_model(df_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Flat Type vs Region\n",
    "flat_type_region(df_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Storey Range vs Region\n",
    "storey_range_region(df_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Resale Price vs Region\n",
    "resale_price_region(df_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Resale Price vs Flat Model\n",
    "resale_price_flat_model(df_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_00overall = df_00.groupby(['region']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Map Visualisation for Overall Average Resale Price per Region\n",
    "map_visual(df_00overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2010 to 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_10= pd.DataFrame(df_10[[\"floor_area_sqm\",\"resale_price\",\"lease_left\"]])\n",
    "numeric_10.reset_index(drop=True, inplace=True)\n",
    "numeric_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the Distributions of All Variables\n",
    "numeric_dist(numeric_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the Correlation Matrix\n",
    "numeric_corr(numeric_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = numeric_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Flat Type vs Flat Model\n",
    "flat_type_flat_model(df_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Flat Type vs Region\n",
    "flat_type_region(df_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Storey Range vs Region\n",
    "storey_range_region(df_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Resale Price vs Region\n",
    "resale_price_region(df_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Resale Price vs Flat Model\n",
    "resale_price_flat_model(df_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10overall = df_10.groupby(['region']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Visualisation for Overall Average Resale Price per Region\n",
    "map_visual(df_10overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2020 onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_20= pd.DataFrame(df_20[[\"floor_area_sqm\",\"resale_price\",\"lease_left\"]])\n",
    "numeric_20.reset_index(drop=True, inplace=True)\n",
    "numeric_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the Distributions of All Variables\n",
    "numeric_dist(numeric_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the Correlation Matrix\n",
    "numeric_corr(numeric_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = numeric_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Flat Type vs Flat Model\n",
    "flat_type_flat_model(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Flat Type vs Region\n",
    "flat_type_region(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Storey Range vs Region\n",
    "storey_range_region(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Resale Price vs Region\n",
    "resale_price_region(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Over Resale Price vs Flat Model\n",
    "resale_price_flat_model(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20overall = df_20.groupby(['region']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Visualisation for Overall Average Resale Price per Region\n",
    "map_visual(df_20overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR EACH YEAR:\n",
    "\n",
    "region, 3 areas in singapore (north-east, central, west)\n",
    "\n",
    "resale price of flat models (3 room, 4 room, 5 room, EA, EM)\n",
    "\n",
    "average resale price/number of units to see the trend\n",
    "\n",
    "FOR EACH GEN:\n",
    "\n",
    "show graph of average and see resale price up or down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat_overall_price = df_cleaned.groupby(['year'])['resale_price'].mean().reset_index()\n",
    "df_flat_type_price = df_cleaned.groupby(['year','flat_type'])['resale_price'].mean().reset_index()\n",
    "df_flat_model_price = df_cleaned.groupby(['year','flat_model'])['resale_price'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat_type_price_3room = df_flat_type_price.loc[df_flat_type_price['flat_type'] == '3 ROOM']\n",
    "df_flat_type_price_4room = df_flat_type_price.loc[df_flat_type_price['flat_type'] == '4 ROOM']\n",
    "df_flat_type_price_5room = df_flat_type_price.loc[df_flat_type_price['flat_type'] == '5 ROOM']\n",
    "df_flat_model_price_ea = df_flat_model_price.loc[df_flat_model_price['flat_model'] == 'APARTMENT']\n",
    "df_flat_model_price_ea['flat_type'] = \"EXECUTIVE APARTMENT\"\n",
    "df_flat_model_price_ma = df_flat_model_price.loc[df_flat_model_price['flat_model'] == 'MAISONETTE']\n",
    "df_flat_model_price_ma['flat_type'] = \"EXECUTIVE MAISONETTE\"\n",
    "df_flat_multiple = pd.concat([df_flat_type_price_3room, df_flat_type_price_4room, df_flat_type_price_5room,\n",
    "                             df_flat_model_price_ea, df_flat_model_price_ma]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_lineplot(df, title):\n",
    "    fig = plt.figure(figsize = (15, 5))\n",
    "    plt.xlabel(\"Years\")\n",
    "    plt.ylabel(\"Resale Price\")\n",
    "    sns.lineplot(data=df, x=\"year\", y=\"resale_price\")\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15, 10))\n",
    "plt.xlabel(\"Years\")\n",
    "plt.ylabel(\"Resale Price\")\n",
    "sns.lineplot(data=df_flat_multiple, x=\"year\", y=\"resale_price\", hue=\"flat_type\")\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "plt.title(\"Overall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_lineplot(df_flat_type_price_3room, \"3 ROOM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_lineplot(df_flat_type_price_4room, \"4 ROOM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_lineplot(df_flat_type_price_5room, \"5 ROOM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_lineplot(df_flat_model_price_ea, \"EXECUTIVE APARTMENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_lineplot(df_flat_model_price_ma, \"EXECUTIVE MAISONETTE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Data: 2020 onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_price = df_20['resale_price']\n",
    "X_test_var = df_20[['floor_area_sqm','lease_left']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data: 1990 to 1999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train90_price = df_90['resale_price']\n",
    "X_train90_var = df_90[['floor_area_sqm', 'lease_left']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(X_train90_var,y_train90_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Intercept \\t a: ', + lm.intercept_)\n",
    "print('Coefficient \\t b: ', + lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(lm.coef_,X_train90_var.columns,columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the coefficients:\n",
    "\n",
    "- Holding all other features fixed, a 1 unit increase in **floor_area_sqm** is associated with an **increase of \\$4156.738117 **.\n",
    "- Holding all other features fixed, a 1 unit increase in **lease_left** is associated with a **decrease of \\$3686.150345 **."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(X_test_var)\n",
    "df_lr_corr = pd.DataFrame(predictions)\n",
    "y_test_price = y_test_price.reset_index(drop=True)\n",
    "df_lr_corr['y_test_price'] = y_test_price\n",
    "df_lr_corr.columns =['predictions','y_test_price']\n",
    "df_lr_corr.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.scatter(y_test_price, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a slight positive correlation (0.404902) between the predictions from the model and the actual test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot((y_test_price-predictions),bins=50, kde=True, height=8)\n",
    "plt.ticklabel_format(style='plain', axis='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A skewed residuals distribution to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('1990')\n",
    "print('Explained Variance (R^2):', lm.score(X_train90_var, y_train90_price))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test_price, predictions))\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test_price, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'R2': lm.score(X_train90_var, y_train90_price),\n",
    "        'MSE': metrics.mean_squared_error(y_test_price, predictions),\n",
    "        'RMSE': np.sqrt(metrics.mean_squared_error(y_test_price, predictions))}]\n",
    "df_lr_90_var = pd.DataFrame(data)\n",
    "df_lr_90_var['Period'] = '90'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data: 2000 to 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train00_price = df_00['resale_price']\n",
    "X_train00_var = df_00[['floor_area_sqm', 'lease_left']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(X_train00_var,y_train00_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Intercept \\t a: ', + lm.intercept_)\n",
    "print('Coefficient \\t b: ', + lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(lm.coef_,X_train00_var.columns,columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the coefficients:\n",
    "\n",
    "- Holding all other features fixed, a 1 unit increase in **floor_area_sqm** is associated with an **increase of \\$3138.643817 **.\n",
    "- Holding all other features fixed, a 1 unit increase in **lease_left** is associated with a **decrease of \\$789.975217 **."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(X_test_var)\n",
    "df_lr_corr = pd.DataFrame(predictions)\n",
    "y_test_price = y_test_price.reset_index(drop=True)\n",
    "df_lr_corr['y_test_price'] = y_test_price\n",
    "df_lr_corr.columns =['predictions','y_test_price']\n",
    "df_lr_corr.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.scatter(y_test_price, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a slight positive correlation (0.57337) between the predictions from the model and the actual test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot((y_test_price-predictions),bins=50, kde=True, height=8)\n",
    "plt.ticklabel_format(style='plain', axis='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A skewed residuals distribution to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('2000')\n",
    "print('Explained Variance (R^2):', lm.score(X_train00_var, y_train00_price))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test_price, predictions))\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test_price, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'R2': lm.score(X_train00_var, y_train00_price),\n",
    "        'MSE': metrics.mean_squared_error(y_test_price, predictions),\n",
    "        'RMSE': np.sqrt(metrics.mean_squared_error(y_test_price, predictions))}]\n",
    "df_lr_00_var = pd.DataFrame(data)\n",
    "df_lr_00_var['Period'] = '00'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data: 2010 to 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train10_price = df_10['resale_price']\n",
    "X_train10_var = df_10[['floor_area_sqm', 'lease_left']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(X_train10_var,y_train10_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Intercept \\t a: ', + lm.intercept_)\n",
    "print('Coefficient \\t b: ', + lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(lm.coef_,X_train10_var.columns,columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the coefficients:\n",
    "\n",
    "- Holding all other features fixed, a 1 unit increase in **floor_area_sqm** is associated with an **increase of \\$3330.597262 **.\n",
    "- Holding all other features fixed, a 1 unit increase in **lease_left** is associated with an **increase of \\$1412.420532 **."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(X_test_var)\n",
    "df_lr_corr = pd.DataFrame(predictions)\n",
    "y_test_price = y_test_price.reset_index(drop=True)\n",
    "df_lr_corr['y_test_price'] = y_test_price\n",
    "df_lr_corr.columns =['predictions','y_test_price']\n",
    "df_lr_corr.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.scatter(y_test_price, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a positive correlation (0.675781) between the predictions from the model and the actual test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot((y_test_price-predictions),bins=50, kde=True, height=8)\n",
    "plt.ticklabel_format(style='plain', axis='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slightly skewed residuals distribution to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('2010')\n",
    "print('Explained Variance (R^2):', lm.score(X_train10_var, y_train10_price))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test_price, predictions))\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test_price, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'R2': lm.score(X_train10_var, y_train10_price),\n",
    "        'MSE': metrics.mean_squared_error(y_test_price, predictions),\n",
    "        'RMSE': np.sqrt(metrics.mean_squared_error(y_test_price, predictions))}]\n",
    "df_lr_10_var = pd.DataFrame(data)\n",
    "df_lr_10_var['Period'] = '10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr_var = pd.concat([df_lr_90_var, df_lr_00_var, df_lr_10_var]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_90.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_90 = pd.DataFrame(df_90[['resale_price']])\n",
    "X_90 = pd.DataFrame(df_90[['flat_type', 'storey_range', 'flat_model', 'region']])\n",
    "X_90.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "replace_values = {'1 ROOM':0,'2 ROOM':1, '3 ROOM':2, '4 ROOM':3, '5 ROOM':4, 'EXECUTIVE':5, 'MULTI GENERATION':6}\n",
    "X_90 = X_90.replace({'flat_type': replace_values})\n",
    "X_90= pd.get_dummies(X_90, columns=['storey_range'], prefix=['storey_range'])\n",
    "X_90= pd.get_dummies(X_90, columns=['flat_model'], prefix=['flat_model'])\n",
    "X_90= pd.get_dummies(X_90, columns=['region'], prefix=['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_90.insert(3, \"storey_range_31 TO 45\", X_90[\"storey_range_16 TO 30\"], True)\n",
    "X_90[\"storey_range_31 TO 45\"] = 0\n",
    "X_90.insert(5, \"flat_model_ADJOINED FLAT\", X_90[\"storey_range_31 TO 45\"], True)\n",
    "X_90.insert(7, \"flat_model_DBSS\", X_90[\"storey_range_31 TO 45\"], True)\n",
    "X_90.insert(9, \"flat_model_LOFT APARTMENT\", X_90[\"storey_range_31 TO 45\"], True)\n",
    "X_90.insert(17, \"flat_model_TYPE S\", X_90[\"storey_range_31 TO 45\"], True)\n",
    "X_90.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_00.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_00 = pd.DataFrame(df_00[['resale_price']])\n",
    "X_00 = pd.DataFrame(df_00[['flat_type', 'storey_range', 'flat_model', 'region']])\n",
    "X_00.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_00 = X_00.replace({'flat_type': replace_values})\n",
    "X_00= pd.get_dummies(X_00, columns=['storey_range'], prefix=['storey_range'])\n",
    "X_00= pd.get_dummies(X_00, columns=['flat_model'], prefix=['flat_model'])\n",
    "X_00= pd.get_dummies(X_00, columns=['region'], prefix=['region'])\n",
    "X_00.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_00.insert(7, \"flat_model_DBSS\", X_90[\"storey_range_31 TO 45\"], True)\n",
    "X_00[\"flat_model_DBSS\"] = 0\n",
    "X_00.insert(9, \"flat_model_LOFT APARTMENT\", X_00[\"flat_model_DBSS\"], True)\n",
    "X_00.insert(17, \"flat_model_TYPE S\", X_00[\"flat_model_DBSS\"], True)\n",
    "X_00.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_10 = pd.DataFrame(df_10[['resale_price']])\n",
    "X_10 = pd.DataFrame(df_10[['flat_type', 'storey_range', 'flat_model', 'region']])\n",
    "X_10.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_values = {'1 ROOM':0,'2 ROOM':1, '3 ROOM':2, '4 ROOM':3, '5 ROOM':4, 'EXECUTIVE':5, 'MULTI GENERATION':6}\n",
    "X_10 = X_10.replace({'flat_type': replace_values})\n",
    "X_10= pd.get_dummies(X_10, columns=['storey_range'], prefix=['storey_range'])\n",
    "X_10= pd.get_dummies(X_10, columns=['flat_model'], prefix=['flat_model'])\n",
    "X_10= pd.get_dummies(X_10, columns=['region'], prefix=['region'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_20 = pd.DataFrame(df_20[['resale_price']])\n",
    "X_20 = pd.DataFrame(df_20[['flat_type', 'storey_range', 'flat_model', 'region']])\n",
    "X_20.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_values = {'1 ROOM':0,'2 ROOM':1, '3 ROOM':2, '4 ROOM':3, '5 ROOM':4, 'EXECUTIVE':5, 'MULTI GENERATION':6}\n",
    "X_20 = X_20.replace({'flat_type': replace_values})\n",
    "X_20= pd.get_dummies(X_20, columns=['storey_range'], prefix=['storey_range'])\n",
    "X_20= pd.get_dummies(X_20, columns=['flat_model'], prefix=['flat_model'])\n",
    "X_20= pd.get_dummies(X_20, columns=['region'], prefix=['region'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1990s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Validation using out-of-bag method\n",
    "rf = RandomForestRegressor(n_estimators=100,oob_score=True, random_state=0)\n",
    "rf.fit(X_90,np.ravel(y_90))\n",
    "predicted_train = rf.predict(X_90)\n",
    "\n",
    "print(f'Out-of-bag R\\u00b2 score estimate (1990s): {rf.oob_score_:>5.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predicted_test = rf.predict(X_20)\n",
    "oob_test_score = r2_score(y_20['resale_price'], predicted_test)\n",
    "spearman = spearmanr(y_20['resale_price'], predicted_test)\n",
    "pearson = pearsonr(y_20['resale_price'], predicted_test)\n",
    "oob_mae = mean_absolute_error(y_20['resale_price'], predicted_test)\n",
    "\n",
    "print(f'1990s Out-of-bag')\n",
    "print(f'Test data R\\u00b2 score: {oob_test_score:>5.3}')\n",
    "print(f'Test data Spearman correlation: {spearman[0]:.3}')\n",
    "print(f'Test data Pearson correlation: {pearson[0]:.3}')\n",
    "print(f'Test data Mean Absolute Error: {round(oob_mae)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# validation by k-fold cross validation with grid search for best hyperparameters\n",
    "# hyperparameter values shown below are the tuned final values\n",
    "param_grid = {\n",
    "    'max_features': ['auto'], # max number of features considered for splitting a node\n",
    "    'max_depth': [20], # max number of levels in each decision tree\n",
    "    'min_samples_split': [15], # min number of data points placed in a node before the node is split\n",
    "    'min_samples_leaf': [2]} # min number of data points allowed in a leaf node\n",
    "rfr =GridSearchCV(RandomForestRegressor(n_estimators = 100, n_jobs=-1, random_state=0),\n",
    "                        param_grid, cv=10, scoring='r2', return_train_score=True)\n",
    "rfr.fit(X_90,np.ravel(y_90))\n",
    "print(\"Best parameters set found on Cross Validation (1990s):\\n\\n\", rfr.best_params_)\n",
    "print(\"\\nCross Validation R\\u00b2 score (1990s):\\n\\n\", rfr.best_score_.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_predicted_test = rfr.predict(X_20)\n",
    "cv_test_score = r2_score(y_20['resale_price'], cv_predicted_test)\n",
    "spearman = spearmanr(y_20['resale_price'], cv_predicted_test)\n",
    "pearson = pearsonr(y_20['resale_price'], cv_predicted_test)\n",
    "cv_mae = mean_absolute_error(y_20['resale_price'], cv_predicted_test)\n",
    "\n",
    "print(f'1990s K-fold cross validation with grid search')\n",
    "print(f'Test data R\\u00b2 score: {cv_test_score:>5.3}')\n",
    "print(f'Test data Spearman correlation: {spearman[0]:.3}')\n",
    "print(f'Test data Pearson correlation: {pearson[0]:.3}')\n",
    "print(f'Test data Mean Absolute Error: {round(cv_mae)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13,20))\n",
    "\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "ax1 = sns.scatterplot(x=y_20['resale_price'], y=predicted_test, edgecolors='w', alpha=0.9, s=8)\n",
    "ax1.set_xlabel('Observed'), ax1.set_xticklabels(['{:,.0f}'.format(x) + 'K' for x in ax1.get_xticks()/1000])\n",
    "ax1.set_ylabel('Predicted'), ax1.set_yticklabels(['{:,.0f}'.format(x) + 'K' for x in ax1.get_yticks()/1000])\n",
    "ax1.annotate('Test R\\u00b2: ' + str(round(oob_test_score,3)) + '\\nTest MAE: ' + str(round(oob_mae)), xy=(0, 1), xytext=(25, -35),\n",
    "    xycoords='axes fraction', textcoords='offset points', fontsize=12)\n",
    "ax1.set_title('Tuned Using Out-Of-Bag (1990s)')\n",
    "\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "ax2 = sns.scatterplot(x=y_20['resale_price'], y=cv_predicted_test, edgecolors='w', alpha=0.9, s=8)\n",
    "ax2.set_xlabel('Observed'), ax2.set_xticklabels(['{:,.0f}'.format(x) + 'K' for x in ax2.get_xticks()/1000])\n",
    "ax2.set_ylabel('Predicted'), ax2.set_yticklabels(['{:,.0f}'.format(x) + 'K' for x in ax2.get_yticks()/1000])\n",
    "ax2.annotate('Test R\\u00b2: ' + str(round(cv_test_score,3)) + '\\nTest MAE: ' + str(round(cv_mae)), xy=(0, 1), xytext=(25, -35),\n",
    "    xycoords='axes fraction', textcoords='offset points', fontsize=12)\n",
    "ax2.set_title('Tuned Using Cross Validation (1990s)')\n",
    "plt.tight_layout(pad=0, rect=[0, 0, 0.9, 0.9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13,15))\n",
    "\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "feat_imp = pd.DataFrame({'Features': X_90.columns, 'Feature Importance': rf.feature_importances_}).sort_values('Feature Importance', ascending=False)\n",
    "sns.barplot(y='Features', x='Feature Importance', data=feat_imp)\n",
    "#plt.xticks(rotation=45, ha='right')\n",
    "ax1.set_title('OOB Feature Importance (1990s)', size=10)\n",
    "\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "feat_imp = pd.DataFrame({'Features': X_90.columns, 'Feature Importance': rfr.best_estimator_.feature_importances_}).sort_values('Feature Importance', ascending=False)\n",
    "sns.barplot(y='Features', x='Feature Importance', data=feat_imp)\n",
    "ax2.set_title('CV Feature Importance (1990s)', size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2000s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation using out-of-bag method\n",
    "rf = RandomForestRegressor(n_estimators=100,oob_score=True, random_state=0)\n",
    "rf.fit(X_00,np.ravel(y_00))\n",
    "predicted_train = rf.predict(X_00)\n",
    "\n",
    "print(f'Out-of-bag R\\u00b2 score estimate (2000s): {rf.oob_score_:>5.3}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test = rf.predict(X_20)\n",
    "oob_test_score = r2_score(y_20['resale_price'], predicted_test)\n",
    "spearman = spearmanr(y_20['resale_price'], predicted_test)\n",
    "pearson = pearsonr(y_20['resale_price'], predicted_test)\n",
    "oob_mae = mean_absolute_error(y_20['resale_price'], predicted_test)\n",
    "\n",
    "print(f'2000s Out-of-bag')\n",
    "print(f'Test data R\\u00b2 score: {oob_test_score:>5.3}')\n",
    "print(f'Test data Spearman correlation: {spearman[0]:.3}')\n",
    "print(f'Test data Pearson correlation: {pearson[0]:.3}')\n",
    "print(f'Test data Mean Absolute Error: {round(oob_mae)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# validation by k-fold cross validation with grid search for best hyperparameters\n",
    "# hyperparameter values shown below are the tuned final values\n",
    "param_grid = {\n",
    "    'max_features': ['auto'], # max number of features considered for splitting a node\n",
    "    'max_depth': [20], # max number of levels in each decision tree\n",
    "    'min_samples_split': [15], # min number of data points placed in a node before the node is split\n",
    "    'min_samples_leaf': [2]} # min number of data points allowed in a leaf node\n",
    "rfr =GridSearchCV(RandomForestRegressor(n_estimators = 100, n_jobs=-1, random_state=0),\n",
    "                        param_grid, cv=10, scoring='r2', return_train_score=True)\n",
    "rfr.fit(X_00,np.ravel(y_00))\n",
    "print(\"Best parameters set found on Cross Validation (2000s):\\n\\n\", rfr.best_params_)\n",
    "print(\"\\nCross Validation R\\u00b2 score (2000s):\\n\\n\", rfr.best_score_.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_predicted_test = rfr.predict(X_20)\n",
    "cv_test_score = r2_score(y_20['resale_price'], cv_predicted_test)\n",
    "spearman = spearmanr(y_20['resale_price'], cv_predicted_test)\n",
    "pearson = pearsonr(y_20['resale_price'], cv_predicted_test)\n",
    "cv_mae = mean_absolute_error(y_20['resale_price'], cv_predicted_test)\n",
    "\n",
    "print(f'2000s K-fold cross validation with grid search')\n",
    "print(f'Test data R\\u00b2 score: {cv_test_score:>5.3}')\n",
    "print(f'Test data Spearman correlation: {spearman[0]:.3}')\n",
    "print(f'Test data Pearson correlation: {pearson[0]:.3}')\n",
    "print(f'Test data Mean Absolute Error: {round(cv_mae)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13,20))\n",
    "\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "ax1 = sns.scatterplot(x=y_20['resale_price'], y=predicted_test, edgecolors='w', alpha=0.9, s=8)\n",
    "ax1.set_xlabel('Observed'), ax1.set_xticklabels(['{:,.0f}'.format(x) + 'K' for x in ax1.get_xticks()/1000])\n",
    "ax1.set_ylabel('Predicted'), ax1.set_yticklabels(['{:,.0f}'.format(x) + 'K' for x in ax1.get_yticks()/1000])\n",
    "ax1.annotate('Test R\\u00b2: ' + str(round(oob_test_score,3)) + '\\nTest MAE: ' + str(round(oob_mae)), xy=(0, 1), xytext=(25, -35),\n",
    "    xycoords='axes fraction', textcoords='offset points', fontsize=12)\n",
    "ax1.set_title('Tuned Using Out-Of-Bag (2000s)')\n",
    "\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "ax2 = sns.scatterplot(x=y_20['resale_price'], y=cv_predicted_test, edgecolors='w', alpha=0.9, s=8)\n",
    "ax2.set_xlabel('Observed'), ax2.set_xticklabels(['{:,.0f}'.format(x) + 'K' for x in ax2.get_xticks()/1000])\n",
    "ax2.set_ylabel('Predicted'), ax2.set_yticklabels(['{:,.0f}'.format(x) + 'K' for x in ax2.get_yticks()/1000])\n",
    "ax2.annotate('Test R\\u00b2: ' + str(round(cv_test_score,3)) + '\\nTest MAE: ' + str(round(cv_mae)), xy=(0, 1), xytext=(25, -35),\n",
    "    xycoords='axes fraction', textcoords='offset points', fontsize=12)\n",
    "ax2.set_title('Tuned Using Cross Validation (2000s)')\n",
    "plt.tight_layout(pad=0, rect=[0, 0, 0.9, 0.9])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(13,15))\n",
    "\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "feat_imp = pd.DataFrame({'Features': X_00.columns, 'Feature Importance': rf.feature_importances_}).sort_values('Feature Importance', ascending=False)\n",
    "sns.barplot(y='Features', x='Feature Importance', data=feat_imp)\n",
    "#plt.xticks(rotation=45, ha='right')\n",
    "ax1.set_title('OOB Feature Importance (2000s)', size=10)\n",
    "\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "feat_imp = pd.DataFrame({'Features': X_00.columns, 'Feature Importance': rfr.best_estimator_.feature_importances_}).sort_values('Feature Importance', ascending=False)\n",
    "sns.barplot(y='Features', x='Feature Importance', data=feat_imp)\n",
    "ax2.set_title('CV Feature Importance (2000s)', size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2010s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation using out-of-bag method\n",
    "rf = RandomForestRegressor(n_estimators=100,oob_score=True, random_state=0)\n",
    "rf.fit(X_10,np.ravel(y_10))\n",
    "predicted_train = rf.predict(X_10)\n",
    "\n",
    "print(f'Out-of-bag R\\u00b2 score estimate (2010s): {rf.oob_score_:>5.3}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test = rf.predict(X_20)\n",
    "oob_test_score = r2_score(y_20['resale_price'], predicted_test)\n",
    "spearman = spearmanr(y_20['resale_price'], predicted_test)\n",
    "pearson = pearsonr(y_20['resale_price'], predicted_test)\n",
    "oob_mae = mean_absolute_error(y_20['resale_price'], predicted_test)\n",
    "\n",
    "print(f'2010s Out-of-bag')\n",
    "print(f'Test data R\\u00b2 score: {oob_test_score:>5.3}')\n",
    "print(f'Test data Spearman correlation: {spearman[0]:.3}')\n",
    "print(f'Test data Pearson correlation: {pearson[0]:.3}')\n",
    "print(f'Test data Mean Absolute Error: {round(oob_mae)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# validation by k-fold cross validation with grid search for best hyperparameters\n",
    "# hyperparameter values shown below are the tuned final values\n",
    "param_grid = {\n",
    "    'max_features': ['auto'], # max number of features considered for splitting a node\n",
    "    'max_depth': [20], # max number of levels in each decision tree\n",
    "    'min_samples_split': [15], # min number of data points placed in a node before the node is split\n",
    "    'min_samples_leaf': [2]} # min number of data points allowed in a leaf node\n",
    "rfr =GridSearchCV(RandomForestRegressor(n_estimators = 100, n_jobs=-1, random_state=0),\n",
    "                        param_grid, cv=10, scoring='r2', return_train_score=True)\n",
    "rfr.fit(X_10,np.ravel(y_10))\n",
    "print(\"Best parameters set found on Cross Validation (2010s):\\n\\n\", rfr.best_params_)\n",
    "print(\"\\nCross Validation R\\u00b2 score (2010s):\\n\\n\", rfr.best_score_.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_predicted_test = rfr.predict(X_20)\n",
    "cv_test_score = r2_score(y_20['resale_price'], cv_predicted_test)\n",
    "spearman = spearmanr(y_20['resale_price'], cv_predicted_test)\n",
    "pearson = pearsonr(y_20['resale_price'], cv_predicted_test)\n",
    "cv_mae = mean_absolute_error(y_20['resale_price'], cv_predicted_test)\n",
    "\n",
    "print(f'2010s K-fold cross validation with grid search')\n",
    "print(f'Test data R\\u00b2 score: {cv_test_score:>5.3}')\n",
    "print(f'Test data Spearman correlation: {spearman[0]:.3}')\n",
    "print(f'Test data Pearson correlation: {pearson[0]:.3}')\n",
    "print(f'Test data Mean Absolute Error: {round(cv_mae)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13,20))\n",
    "\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "ax1 = sns.scatterplot(x=y_20['resale_price'], y=predicted_test, edgecolors='w', alpha=0.9, s=8)\n",
    "ax1.set_xlabel('Observed'), ax1.set_xticklabels(['{:,.0f}'.format(x) + 'K' for x in ax1.get_xticks()/1000])\n",
    "ax1.set_ylabel('Predicted'), ax1.set_yticklabels(['{:,.0f}'.format(x) + 'K' for x in ax1.get_yticks()/1000])\n",
    "ax1.annotate('Test R\\u00b2: ' + str(round(oob_test_score,3)) + '\\nTest MAE: ' + str(round(oob_mae)), xy=(0, 1), xytext=(25, -35),\n",
    "    xycoords='axes fraction', textcoords='offset points', fontsize=12)\n",
    "ax1.set_title('Tuned Using Out-Of-Bag (2010s)')\n",
    "\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "ax2 = sns.scatterplot(x=y_20['resale_price'], y=cv_predicted_test, edgecolors='w', alpha=0.9, s=8)\n",
    "ax2.set_xlabel('Observed'), ax2.set_xticklabels(['{:,.0f}'.format(x) + 'K' for x in ax2.get_xticks()/1000])\n",
    "ax2.set_ylabel('Predicted'), ax2.set_yticklabels(['{:,.0f}'.format(x) + 'K' for x in ax2.get_yticks()/1000])\n",
    "ax2.annotate('Test R\\u00b2: ' + str(round(cv_test_score,3)) + '\\nTest MAE: ' + str(round(cv_mae)), xy=(0, 1), xytext=(25, -35),\n",
    "    xycoords='axes fraction', textcoords='offset points', fontsize=12)\n",
    "ax2.set_title('Tuned Using Cross Validation (2010s)')\n",
    "plt.tight_layout(pad=0, rect=[0, 0, 0.9, 0.9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13,15))\n",
    "\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "feat_imp = pd.DataFrame({'Features': X_10.columns, 'Feature Importance': rf.feature_importances_}).sort_values('Feature Importance', ascending=False)\n",
    "sns.barplot(y='Features', x='Feature Importance', data=feat_imp)\n",
    "#plt.xticks(rotation=45, ha='right')\n",
    "ax1.set_title('OOB Feature Importance (2010s)', size=10)\n",
    "\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "feat_imp = pd.DataFrame({'Features': X_10.columns, 'Feature Importance': rfr.best_estimator_.feature_importances_}).sort_values('Feature Importance', ascending=False)\n",
    "sns.barplot(y='Features', x='Feature Importance', data=feat_imp)\n",
    "ax2.set_title('CV Feature Importance (2010s)', size=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
